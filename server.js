// const express = require('express');
// const bodyParser = require('body-parser');
// const twilio = require('twilio');
// const path = require('path');
// const fs = require('fs');
// const { Groq } = require('groq-sdk');
// const fetch = require('node-fetch');
// const { SarvamAIClient } = require('sarvamai');
// const { spawn } = require('child_process');

// const app = express();

// const accountSID = '';
// const authToken = '';
// const client = require('twilio')(accountSID, authToken);

// const NGROK_DOMAIN = 'https://11fe57f06637.ngrok-free.app';
// const GROQ_API_KEY = '';
// const groq = new Groq({ apiKey: GROQ_API_KEY });

// app.use('/static', express.static(path.join(__dirname, 'public'), {
//   setHeaders: (res, filePath) => {
//     if (filePath.endsWith('.mp3')) {
//       res.setHeader('Content-Type', 'audio/mpeg');
//     }
//   }
// }));

// app.use(bodyParser.urlencoded({ extended: false }));

// const userState = {};

// async function downloadTwilioImage(url, fileName) {
//   const res = await fetch(url, {
//     headers: {
//       'Authorization': 'Basic ' + Buffer.from(`${accountSID}:${authToken}`).toString('base64')
//     }
//   });
//   const buffer = await res.buffer();
//   const filePath = path.join(__dirname, 'public', fileName);
//   fs.writeFileSync(filePath, buffer);
//   return `${NGROK_DOMAIN}/static/${fileName}`;
// }

// async function translateText(text, targetLang) {
//   const res = await fetch(`https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=${targetLang}&dt=t&q=${encodeURIComponent(text)}`);
//   const data = await res.json();
//   return data[0].map(part => part[0]).join('');
// }

// app.post('/whatsapp-webhook', async (req, res) => {
//   const from = req.body.From;
//   const timestamp = Date.now();
//   const incomingMsg = req.body.Body?.toLowerCase().trim();
//   const mediaUrl = req.body.MediaUrl0;
//   const contentType = req.body.MediaContentType0;

//   try {
//     const langMap = {
//       '1': { code: 'hi', label: 'Hindi' },
//       '2': { code: 'en', label: 'English' },
//       '3': { code: 'bn', label: 'Bengali' },
//       '4': { code: 'ta', label: 'Tamil' },
//       '5': { code: 'te', label: 'Telugu' },
//       '6': { code: 'kn', label: 'Kannada' },
//       '7': { code: 'ml', label: 'Malayalam' },
//       '8': { code: 'mr', label: 'Marathi' },
//       '9': { code: 'gu', label: 'Gujarati' }
//     };

//     if (userState[from]?.waitingForLanguage && incomingMsg) {
//       const selectedLang = langMap[incomingMsg];
//       if (!selectedLang) {
//         await client.messages.create({
//           from: 'whatsapp:+14155238886',
//           to: from,
//           body: 'âŒ Invalid option. Please reply with a valid number.'
//         });
//         return res.sendStatus(200);
//       }

//       let translated = await translateText(userState[from].summary, selectedLang.code);
//       if (!translated || translated.trim() === '') translated = userState[from].summary;

//       const sarvamClient = new SarvamAIClient({ apiSubscriptionKey: 'sk_9neln2iw_KtLl05f0AmDGSDOuitOjvV3N' });
//       const langCodeMap = {
//         hi: 'hi-IN', en: 'en-IN', bn: 'bn-IN', ta: 'ta-IN',
//         te: 'te-IN', kn: 'kn-IN', ml: 'ml-IN', mr: 'mr-IN', gu: 'gu-IN'
//       };

//       const audioRes = await sarvamClient.textToSpeech.convert({
//         text: translated,
//         target_language_code: langCodeMap[selectedLang.code] || selectedLang.code,
//         speaker: 'anushka',
//         model: 'bulbul:v2',
//         pitch: 0, pace: 1, loudness: 1, speech_sample_rate: 22050,
//         enable_preprocessing: true
//       });

//       const audioBuffer = Buffer.from(audioRes.audios[0], 'base64');
//       const rawPath = path.join(__dirname, 'public', `audio_${timestamp}.raw`);
//       const mp3Path = path.join(__dirname, 'public', `audio_${timestamp}.mp3`);
//       const audioURL = `${NGROK_DOMAIN}/static/audio_${timestamp}.mp3`;

//       fs.writeFileSync(rawPath, audioBuffer);

//       await new Promise((resolve, reject) => {
//         const ffmpeg = spawn('ffmpeg', [
//           '-f', 's16le', '-ar', '22050', '-ac', '1',
//           '-i', rawPath,
//           '-acodec', 'libmp3lame', '-ab', '128k',
//           mp3Path
//         ]);
//         ffmpeg.stderr.on('data', data => console.error('ffmpeg:', data.toString()));
//         ffmpeg.on('close', code => code === 0 ? resolve() : reject(new Error('ffmpeg failed')));
//       });

//       await new Promise(resolve => setTimeout(resolve, 5000));

//       await client.messages.create({
//         from: 'whatsapp:+14155238886',
//         to: from,
//         body: `ðŸŽ§ Here's your summary audio in ${selectedLang.label}:`,
//         mediaUrl: [audioURL]
//       });

//       delete userState[from];
//       return res.sendStatus(200);
//     }

//     if (mediaUrl && contentType?.startsWith('image')) {
//       const localImageFile = `twilio_img_${timestamp}.jpg`;
//       const groqImageUrl = await downloadTwilioImage(mediaUrl, localImageFile);

//       const chatCompletion = await groq.chat.completions.create({
//         messages: [
//           {
//             role: 'user',
//             content: [
//               { type: 'text', text: 'From this medical image, extract only the relevant prescription and rewrite it in plain English as simple, spoken patient instructions. Do NOT include headings, metadata, or explanations. No markdown. Only the final clean instructions.' },
//               { type: 'image_url', image_url: { url: groqImageUrl } }
//             ]
//           }
//         ],
//         model: 'meta-llama/llama-4-scout-17b-16e-instruct',
//         temperature: 0.3,
//         max_completion_tokens: 1024,
//         top_p: 1,
//         stream: false
//       });

//       const summary = chatCompletion.choices[0].message.content.replace(/[\*\_\~\`]/g, '').split('\n\n').pop().trim();
//       userState[from] = { waitingForLanguage: true, summary };

//       await client.messages.create({
//         from: 'whatsapp:+14155238886',
//         to: from,
//         body:
//           'ðŸ—£ï¸ In which language would you like to hear the summary?\n' +
//           '1. Hindi\n2. English\n3. Bengali\n4. Tamil\n5. Telugu\n6. Kannada\n7. Malayalam\n8. Marathi\n9. Gujarati\n' +
//           '\nðŸ‘‰ Reply with the number (1â€“9).'
//       });
//       return res.sendStatus(200);
//     }

//     res.status(200).send();
//   } catch (err) {
//     console.error('âŒ Error:', err.message);
//     res.status(500).send();
//   }
// });

// app.listen(3000, () => {
//   console.log('ðŸ“¡ WhatsApp OCR + Groq bot running on http://localhost:3000');
// });


require('dotenv').config();
const express = require('express');
const bodyParser = require('body-parser');
const twilio = require('twilio');
const path = require('path');
const fs = require('fs');
const { Groq } = require('groq-sdk');
const fetch = require('node-fetch');
const { SarvamAIClient } = require('sarvamai');
const { spawn } = require('child_process');
const FormData = require('form-data');

const app = express();

const accountSID = process.env.TWILIO_SID;
const authToken = process.env.TWILIO_AUTH_TOKEN;
const client = twilio(accountSID, authToken);

const NGROK_DOMAIN = process.env.NGROK_DOMAIN;
const GROQ_API_KEY = process.env.GROQ_API_KEY;
const groq = new Groq({ apiKey: GROQ_API_KEY });

const sarvamClient = new SarvamAIClient({ apiSubscriptionKey: process.env.SARVAM_API_KEY });

app.use('/static', express.static(path.join(__dirname, 'public'), {
  setHeaders: (res, filePath) => {
    if (filePath.endsWith('.mp3')) {
      res.setHeader('Content-Type', 'audio/mpeg');
    }
  }
}));
app.use(bodyParser.urlencoded({ extended: false }));

const userState = {};

async function downloadTwilioImage(url, fileName) {
  const res = await fetch(url, {
    headers: {
      'Authorization': 'Basic ' + Buffer.from(`${accountSID}:${authToken}`).toString('base64')
    }
  });
  const buffer = await res.buffer();
  const filePath = path.join(__dirname, 'public', fileName);
  fs.writeFileSync(filePath, buffer);
  return `${NGROK_DOMAIN}/static/${fileName}`;
}

async function translateText(text, targetLang) {
  const res = await fetch(`https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=${targetLang}&dt=t&q=${encodeURIComponent(text)}`);
  const data = await res.json();
  return data[0].map(part => part[0]).join('');
}

app.post('/whatsapp-webhook', async (req, res) => {
  const from = req.body.From;
  const timestamp = Date.now();
  const incomingMsg = req.body.Body?.toLowerCase().trim();
  const mediaUrl = req.body.MediaUrl0;
  const contentType = req.body.MediaContentType0;

  try {
    const langMap = {
      '1': { code: 'hi', label: 'Hindi' },
      '2': { code: 'en', label: 'English' },
      '3': { code: 'bn', label: 'Bengali' },
      '4': { code: 'ta', label: 'Tamil' },
      '5': { code: 'te', label: 'Telugu' },
      '6': { code: 'kn', label: 'Kannada' },
      '7': { code: 'ml', label: 'Malayalam' },
      '8': { code: 'mr', label: 'Marathi' },
      '9': { code: 'gu', label: 'Gujarati' }
    };

    const langCodeMap = {
      hi: 'hi-IN', en: 'en-IN', bn: 'bn-IN', ta: 'ta-IN',
      te: 'te-IN', kn: 'kn-IN', ml: 'ml-IN', mr: 'mr-IN', gu: 'gu-IN'
    };

    // âœ… VOICE FOLLOW-UP HANDLER
    if (mediaUrl && contentType?.startsWith('audio') && userState[from]?.expectingVoice) {
      const oggFile = `voice_${timestamp}.ogg`;
      const wavFile = `voice_${timestamp}.wav`;
      const oggPath = path.join(__dirname, 'public', oggFile);
      const wavPath = path.join(__dirname, 'public', wavFile);

      await downloadTwilioImage(mediaUrl, oggFile);

      await new Promise((resolve, reject) => {
        const ffmpeg = spawn('ffmpeg', ['-i', oggPath, '-ar', '16000', '-ac', '1', wavPath]);
        ffmpeg.stderr.on('data', data => console.error('ffmpeg:', data.toString()));
        ffmpeg.on('close', code => code === 0 ? resolve() : reject(new Error('FFmpeg failed')));
      });

      const form = new FormData();
      form.append('file', fs.createReadStream(wavPath));
      form.append('model', 'saarika:v2.5');
      form.append('language_code', 'unknown');

      const response = await fetch('https://api.sarvam.ai/speech-to-text', {
        method: 'POST',
        headers: {
          'api-subscription-key': process.env.SARVAM_API_KEY,
          ...form.getHeaders()
        },
        body: form
      });

      const result = await response.json();
      const transcript = result.transcript || 'Sorry, could not understand the audio.';

      await client.messages.create({
        from: 'whatsapp:+14155238886',
        to: from,
        body: `ðŸ—¨ï¸ Transcribed: ${transcript}\n\nðŸ’¡ Processing your question...`
      });

      // â¬‡ï¸ Ask Groq using prescription + question
      const prevSummary = userState[from]?.summary || '';
      const langCode = userState[from]?.languageCode || 'en-IN';
      const langLabel = userState[from]?.languageLabel || 'English';

      const chatResponse = await groq.chat.completions.create({
        messages: [
          {
            role: 'user',
            content: `You are a helpful healthcare assistant. The following is a prescription summary:\n\n"${prevSummary}"\n\nNow, the user asked:\n"${transcript}"\n\nBased on the prescription and question, provide a simple, helpful response.`
          }
        ],
        model: 'llama-3.3-70b-versatile',
        temperature: 0.5,
        max_completion_tokens: 512,
        top_p: 1
      });
      const replyText = chatResponse.choices[0].message.content.trim();

      // ðŸ—£ï¸ Convert answer to speech
      const audioRes = await sarvamClient.textToSpeech.convert({
        text: replyText,
        target_language_code: langCode,
        speaker: 'anushka',
        model: 'bulbul:v2',
        pitch: 0, pace: 1, loudness: 1, speech_sample_rate: 22050,
        enable_preprocessing: true
      });

      const answerRaw = Buffer.from(audioRes.audios[0], 'base64');
      const rawAnswerPath = path.join(__dirname, 'public', `answer_${timestamp}.raw`);
      const mp3AnswerPath = path.join(__dirname, 'public', `answer_${timestamp}.mp3`);
      const audioAnswerURL = `${NGROK_DOMAIN}/static/answer_${timestamp}.mp3`;

      fs.writeFileSync(rawAnswerPath, answerRaw);

      await new Promise((resolve, reject) => {
        const ffmpeg = spawn('ffmpeg', [
          '-f', 's16le', '-ar', '22050', '-ac', '1',
          '-i', rawAnswerPath,
          '-acodec', 'libmp3lame', '-ab', '128k',
          mp3AnswerPath
        ]);
        ffmpeg.stderr.on('data', data => console.error('ffmpeg:', data.toString()));
        ffmpeg.on('close', code => code === 0 ? resolve() : reject(new Error('ffmpeg failed')));
      });

      await new Promise(resolve => setTimeout(resolve, 5000));

      await client.messages.create({
        from: 'whatsapp:+14155238886',
        to: from,
        body: `ðŸ¤– Here's the answer to your question in ${langLabel}:`,
        mediaUrl: [audioAnswerURL]
      });

      return res.sendStatus(200);
    }

    // âœ… LANGUAGE SELECTION HANDLER
    if (userState[from]?.waitingForLanguage && incomingMsg) {
      const selectedLang = langMap[incomingMsg];
      if (!selectedLang) {
        await client.messages.create({
          from: 'whatsapp:+14155238886',
          to: from,
          body: 'âŒ Invalid option. Please reply with a valid number.'
        });
        return res.sendStatus(200);
      }

      let translated = await translateText(userState[from].summary, selectedLang.code);
      if (!translated || translated.trim() === '') translated = userState[from].summary;

      const audioRes = await sarvamClient.textToSpeech.convert({
        text: translated,
        target_language_code: langCodeMap[selectedLang.code],
        speaker: 'anushka',
        model: 'bulbul:v2',
        pitch: 0, pace: 1, loudness: 1, speech_sample_rate: 22050,
        enable_preprocessing: true
      });

      const audioBuffer = Buffer.from(audioRes.audios[0], 'base64');
      const rawPath = path.join(__dirname, 'public', `audio_${timestamp}.raw`);
      const mp3Path = path.join(__dirname, 'public', `audio_${timestamp}.mp3`);
      const audioURL = `${NGROK_DOMAIN}/static/audio_${timestamp}.mp3`;

      fs.writeFileSync(rawPath, audioBuffer);

      await new Promise((resolve, reject) => {
        const ffmpeg = spawn('ffmpeg', [
          '-f', 's16le', '-ar', '22050', '-ac', '1',
          '-i', rawPath,
          '-acodec', 'libmp3lame', '-ab', '128k',
          mp3Path
        ]);
        ffmpeg.stderr.on('data', data => console.error('ffmpeg:', data.toString()));
        ffmpeg.on('close', code => code === 0 ? resolve() : reject(new Error('ffmpeg failed')));
      });

      await new Promise(resolve => setTimeout(resolve, 5000));

      await client.messages.create({
        from: 'whatsapp:+14155238886',
        to: from,
        body: `ðŸŽ§ Here's your summary audio in ${selectedLang.label}:`,
        mediaUrl: [audioURL]
      });

      userState[from].waitingForLanguage = false;
      userState[from].expectingVoice = true;
      userState[from].languageCode = langCodeMap[selectedLang.code];
      userState[from].languageLabel = selectedLang.label;

      await client.messages.create({
        from: 'whatsapp:+14155238886',
        to: from,
        body: 'ðŸŽ¤ You can now send voice notes to ask questions about the prescription.'
      });

      return res.sendStatus(200);
    }

    // âœ… PRESCRIPTION IMAGE HANDLER
    if (mediaUrl && contentType?.startsWith('image')) {
      const localImageFile = `twilio_img_${timestamp}.jpg`;
      const groqImageUrl = await downloadTwilioImage(mediaUrl, localImageFile);

      const chatCompletion = await groq.chat.completions.create({
        messages: [
          {
            role: 'user',
            content: [
              { type: 'text', text: 'From this medical image, extract only the relevant prescription and rewrite it in plain English as simple, spoken patient instructions. Do NOT include headings, metadata, or explanations. No markdown. Only the final clean instructions.' },
              { type: 'image_url', image_url: { url: groqImageUrl } }
            ]
          }
        ],
        model: 'meta-llama/llama-4-scout-17b-16e-instruct',
        temperature: 0.3,
        max_completion_tokens: 1024,
        top_p: 1,
        stream: false
      });

      const summary = chatCompletion.choices[0].message.content.replace(/[\*\_\~\`]/g, '').split('\n\n').pop().trim();
      userState[from] = { waitingForLanguage: true, summary, expectingVoice: false };
      // ðŸŽ§ Speak language list
const languageList = `
à¥§ à¤¹à¤¿à¤‚à¤¦à¥€
2 English
à§© à¦¬à¦¾à¦‚à¦²à¦¾
4 à®¤à®®à®¿à®´à¯
5 à°¤à±†à°²à±à°—à±
6 à²•à²¨à³à²¨à²¡
7 à´®à´²à´¯à´¾à´³à´‚
8 à¤®à¤°à¤¾à¤ à¥€
9 àª—à«àªœàª°àª¾àª¤à«€

à¤•à¥ƒà¤ªà¤¯à¤¾ à¤…à¤ªà¤¨à¥€ à¤ªà¤¸à¤‚à¤¦ à¤•à¥€ à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤¨à¤‚à¤¬à¤° à¤­à¥‡à¤œà¥‡à¤‚à¥¤
`;

const langAudio = await sarvamClient.textToSpeech.convert({
  text: languageList,
  target_language_code: 'hi-IN',
  speaker: 'anushka',
  model: 'bulbul:v2',
  pitch: 0, pace: 1, loudness: 1, speech_sample_rate: 22050,
  enable_preprocessing: true
});

const langBuffer = Buffer.from(langAudio.audios[0], 'base64');
const rawLangPath = path.join(__dirname, 'public', `langselect_${timestamp}.raw`);
const mp3LangPath = path.join(__dirname, 'public', `langselect_${timestamp}.mp3`);
const langAudioURL = `${NGROK_DOMAIN}/static/langselect_${timestamp}.mp3`;

fs.writeFileSync(rawLangPath, langBuffer);

await new Promise((resolve, reject) => {
  const ffmpeg = spawn('ffmpeg', [
    '-f', 's16le', '-ar', '22050', '-ac', '1',
    '-i', rawLangPath,
    '-acodec', 'libmp3lame', '-ab', '128k',
    mp3LangPath
  ]);
  ffmpeg.stderr.on('data', data => console.error('ffmpeg:', data.toString()));
  ffmpeg.on('close', code => code === 0 ? resolve() : reject(new Error('ffmpeg failed')));
});

await new Promise(resolve => setTimeout(resolve, 1000));

await client.messages.create({
  from: 'whatsapp:+14155238886',
  to: from,
  body: `ðŸŽ™ï¸ Please listen and reply with a number (1â€“9) to select your language.`,
  mediaUrl: [langAudioURL]
});
      await client.messages.create({
        from: 'whatsapp:+14155238886',
        to: from,
        body:
          'ðŸ—£ï¸ In which language would you like to hear the summary?\n' +
          '1. à¤¹à¤¿à¤‚à¤¦à¥€\n2. English\n3. à¦¬à¦¾à¦‚à¦²à¦¾\n4. à®¤à®®à®¿à®´à¯\n5. à°¤à±†à°²à±à°—à±\n6. à²•à²¨à³à²¨à²¡\n7.à´®à´²à´¯à´¾à´³à´‚ \n8. à¤®à¤°à¤¾à¤ à¥€\n9. àª—à«àªœàª°àª¾àª¤à«€\n' +
          '\nðŸ‘‰ Reply with the number (1â€“9).'
      });

    }
    res.sendStatus(200);
  } catch (err) {
    console.error('âŒ Error:', err.message);
    res.sendStatus(500);
  }
});

app.listen(3000, () => {
  console.log('ðŸ“¡ WhatsApp OCR + Voice Bot running on http://localhost:3000');
});
